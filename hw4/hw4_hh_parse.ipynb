{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "============================================================================\n",
        "# ПАЙПЛАЙН ОБРАБОТКИ ДАННЫХ С ПАТТЕРНОМ \"ЦЕПОЧКА ОТВЕТСТВЕННОСТИ\"\n",
        "============================================================================"
      ],
      "metadata": {
        "id": "wVDeNsi5unu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Пайплайн для предобработки данных о вакансиях.\n",
        "Использует паттерн \"Цепочка ответственности\" для последовательной обработки.\n",
        "Результат: X (признаки) и y (таргет) в формате numpy (.npy)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "BxDNwwJjuwr3",
        "outputId": "73e9ec3f-2e2a-4b16-bfc5-24c7c8a94557"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nПайплайн для предобработки данных о вакансиях.\\nИспользует паттерн \"Цепочка ответственности\" для последовательной обработки.\\nРезультат: X (признаки) и y (таргет) в формате numpy (.npy)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1rw8QcRZHAlw"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "# Cтандартные библиотеки\n",
        "import argparse\n",
        "import logging\n",
        "import re\n",
        "from abc import ABC, abstractmethod\n",
        "from pathlib import Path\n",
        "from typing import Optional, Sequence, Tuple, List, Dict, Any\n",
        "\n",
        "# Сторонние модули\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Настройка логирования\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\"\n",
        ")\n",
        "logger = logging.getLogger(\"salary_pipeline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================================\n",
        "## БАЗОВЫЙ КЛАСС ОБРАБОТЧИКА (ЦЕПОЧКА ОТВЕТСТВЕННОСТИ)\n",
        "============================================================================"
      ],
      "metadata": {
        "id": "2qmdx6A5vEfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HandlerBase(ABC):\n",
        "    \"\"\"Базовый абстрактный обработчик цепочки ответственности.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self._next_handler: Optional[\"HandlerBase\"] = None\n",
        "\n",
        "    def link_next(self, handler: \"HandlerBase\") -> \"HandlerBase\":\n",
        "        \"\"\"Присоединить следующий обработчик и вернуть его (чтобы можно было цепочкой).\"\"\"\n",
        "        self._next_handler = handler\n",
        "        return handler\n",
        "\n",
        "    def execute(self, df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Выполнить текущую логику и передать результат дальше, если есть следующий.\"\"\"\n",
        "        result = self._run(df)\n",
        "        if self._next_handler is not None:\n",
        "            return self._next_handler.execute(result)\n",
        "        return result\n",
        "\n",
        "    @abstractmethod\n",
        "    def _run(self, df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "NmpdMTbWIVdl"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================================\n",
        "## КОНКРЕТНЫЕ ОБРАБОТЧИКИ\n",
        "============================================================================"
      ],
      "metadata": {
        "id": "eYTdZWSPvMoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CSVSource(HandlerBase):\n",
        "    \"\"\"Загружает CSV в DataFrame, пробуя несколько кодировок.\n",
        "\n",
        "    Использует engine='python' для корректной обработки полей в кавычках с новыми строками.\n",
        "    \"\"\"\n",
        "\n",
        "    DEFAULT_ENCODINGS: Sequence[str] = (\"utf-8\", \"cp1251\", \"latin1\")\n",
        "\n",
        "    def __init__(self, csv_path: Path | str, encodings: Optional[Sequence[str]] = None, **read_csv_kwargs) -> None:\n",
        "        super().__init__()\n",
        "        self.path = Path(csv_path)\n",
        "        self.encodings = tuple(encodings) if encodings is not None else self.DEFAULT_ENCODINGS\n",
        "        self.read_csv_kwargs = read_csv_kwargs\n",
        "\n",
        "    def _run(self, df: Optional[pd.DataFrame]) -> pd.DataFrame:\n",
        "        if not self.path.exists():\n",
        "            raise FileNotFoundError(f\"CSV file not found: {self.path}\")\n",
        "\n",
        "        for enc in self.encodings:\n",
        "            try:\n",
        "                logger.info(\"Reading %s with encoding=%s\", self.path, enc)\n",
        "                loaded = pd.read_csv(\n",
        "                    self.path,\n",
        "                    sep=\",\",\n",
        "                    quotechar='\"',\n",
        "                    engine=\"python\",\n",
        "                    encoding=enc,\n",
        "                    index_col=0,\n",
        "                    **self.read_csv_kwargs,\n",
        "                )\n",
        "                # чуть-чуть нормализуем имена колонок\n",
        "                loaded.columns = [str(c).strip() for c in loaded.columns]\n",
        "                logger.info(\"Loaded dataframe shape=%s (encoding=%s)\", loaded.shape, enc)\n",
        "                return loaded\n",
        "            except Exception as exc:\n",
        "                logger.debug(\"Cannot read %s with %s: %s\", self.path, enc, exc)\n",
        "        raise RuntimeError(f\"Failed to parse CSV with encodings: {self.encodings}\")"
      ],
      "metadata": {
        "id": "rM1uUGfOvp4O"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextSanitizer(HandlerBase):\n",
        "    \"\"\"Очищает текстовые поля: удаляет BOM, неразрывные пробелы, управляющие и непечатаемые символы.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_text(value):\n",
        "        if not isinstance(value, str):\n",
        "            return value\n",
        "        # убрать BOM и NBSP\n",
        "        s = value.replace(\"\\ufeff\", \"\").replace(\"\\xa0\", \"\")\n",
        "        # заменить табы/переводы строк на пробел\n",
        "        s = re.sub(r\"[\\t\\n\\r]+\", \" \", s)\n",
        "        # оставить только печатные символы\n",
        "        s = \"\".join(ch for ch in s if ch.isprintable())\n",
        "        # сжать последовательности пробелов\n",
        "        s = re.sub(r\"\\s+\", \" \", s)\n",
        "        return s.strip()\n",
        "\n",
        "    def _run(self, df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        if df is None:\n",
        "            return None\n",
        "        res = df.copy()\n",
        "        text_columns = res.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "        for col in text_columns:\n",
        "            res[col] = res[col].map(self._clean_text)\n",
        "        return res"
      ],
      "metadata": {
        "id": "G-iKfxW5vrcB"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SalaryConverter(HandlerBase):\n",
        "    \"\"\"Преобразует колонку с зарплатой в числовую рублёвую величину.\"\"\"\n",
        "\n",
        "    RATES = {\n",
        "        \"rub\": 1.0,\n",
        "        \"руб\": 1.0,\n",
        "        \"руб.\": 1.0,\n",
        "        \"usd\": 77.8332,\n",
        "        \"eur\": 90.5366,\n",
        "        \"kzt\": 0.15233,\n",
        "        \"uah\": 1.79369,\n",
        "        \"kgs\": 0.890031,\n",
        "        \"byn\": 26.8381,\n",
        "        \"azn\": 45.7842,\n",
        "        \"gbp\": 104.1953,\n",
        "        \"cny\": 11.151,\n",
        "    }\n",
        "\n",
        "    def __init__(self, salary_col: str = \"ЗП\") -> None:\n",
        "        super().__init__()\n",
        "        self.salary_col = salary_col\n",
        "\n",
        "    def _run(self, df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        if df is None or self.salary_col not in df.columns:\n",
        "            return df\n",
        "\n",
        "        res = df.copy()\n",
        "\n",
        "        # число (поддержка десятичных через запятую/точку)\n",
        "        num_series = res[self.salary_col].astype(str).str.extract(r\"(\\d+[.,]?\\d*)\")[0]\n",
        "        num_series = num_series.str.replace(\",\", \".\").astype(float)\n",
        "\n",
        "        # валюта — берем буквы, если есть\n",
        "        curr_series = res[self.salary_col].astype(str).str.extract(r\"([A-Za-zА-Яа-яёЁ\\.]+)\")[0].fillna(\"\")\n",
        "        curr_series = curr_series.str.lower()\n",
        "\n",
        "        def to_rub(val, curr):\n",
        "            if pd.isna(val):\n",
        "                return None\n",
        "            rate = self.RATES.get(curr, self.RATES.get(curr.rstrip(\".\"), 1.0))\n",
        "            return val * rate\n",
        "\n",
        "        res[self.salary_col] = [\n",
        "            to_rub(v, c) for v, c in zip(num_series.tolist(), curr_series.tolist())\n",
        "        ]\n",
        "        return res"
      ],
      "metadata": {
        "id": "M3Ogoc3N1th9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SalaryOutlierHandler(HandlerBase):\n",
        "    \"\"\"Обработка выбросов в таргете через IQR.\n",
        "\n",
        "    strategy: 'clip' | 'remove' | 'nan'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target: str = \"ЗП\", factor: float = 1.5, strategy: str = \"clip\") -> None:\n",
        "        super().__init__()\n",
        "        self.target = target\n",
        "        self.factor = factor\n",
        "        self.strategy = strategy\n",
        "\n",
        "    def _run(self, df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        if df is None or self.target not in df.columns:\n",
        "            return df\n",
        "\n",
        "        res = df.copy()\n",
        "        q1 = res[self.target].quantile(0.25)\n",
        "        q3 = res[self.target].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "\n",
        "        lower = q1 - self.factor * iqr\n",
        "        upper = q3 + self.factor * iqr\n",
        "\n",
        "        out_mask = (res[self.target] < lower) | (res[self.target] > upper)\n",
        "\n",
        "        if self.strategy == \"clip\":\n",
        "            res[self.target] = res[self.target].clip(lower=lower, upper=upper)\n",
        "        elif self.strategy == \"remove\":\n",
        "            res = res.loc[~out_mask].reset_index(drop=True)\n",
        "        elif self.strategy == \"nan\":\n",
        "            res.loc[out_mask, self.target] = None\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown strategy: {self.strategy}\")\n",
        "        return res"
      ],
      "metadata": {
        "id": "bkKl-MZZ1wWe"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataCompleteness(HandlerBase):\n",
        "    \"\"\"Работа с полнотой данных: удаление дубликатов, плохих колонок и заполнение NaN.\"\"\"\n",
        "\n",
        "    def __init__(self, drop_duplicates: bool = True, drop_threshold: float = 0.5) -> None:\n",
        "        super().__init__()\n",
        "        self.drop_duplicates = drop_duplicates\n",
        "        self.drop_threshold = drop_threshold\n",
        "\n",
        "    def _run(self, df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        if df is None:\n",
        "            return None\n",
        "\n",
        "        res = df.copy()\n",
        "\n",
        "        # дубликаты (только при достаточно большом наборе)\n",
        "        if self.drop_duplicates and res.shape[0] > 100:\n",
        "            res = res.drop_duplicates()\n",
        "\n",
        "        # удалить колонки с большим количеством NaN\n",
        "        thresh = int(self.drop_threshold * len(res))\n",
        "        res = res.dropna(axis=1, thresh=thresh)\n",
        "\n",
        "        # числовые: заполнить медианой\n",
        "        num_cols = res.select_dtypes(include=[\"number\"]).columns\n",
        "        for c in num_cols:\n",
        "            res[c] = res[c].fillna(res[c].median())\n",
        "\n",
        "        # категориальные: пометить как missing\n",
        "        cat_cols = res.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "        for c in cat_cols:\n",
        "            res[c] = res[c].fillna(\"__missing__\")\n",
        "        return res"
      ],
      "metadata": {
        "id": "Sy9hFOZC1yzc"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================================\n",
        "## ГЛАВНЫЙ КОДИРОВЩИК (КООРДИНАТОР)\n",
        "============================================================================"
      ],
      "metadata": {
        "id": "0nNKSEXn3SSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProfileEncoder(HandlerBase):\n",
        "    \"\"\"Feature encoder — компактно организованные хелперы + отдельные энкодеры по колонкам.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    # ---------------- utilities ----------------\n",
        "\n",
        "    @staticmethod\n",
        "    def _gender_from_text(txt) -> Optional[int]:\n",
        "        if not isinstance(txt, str):\n",
        "            return None\n",
        "        t = txt.lower()\n",
        "        if \"муж\" in t or \"male\" in t:\n",
        "            return 1\n",
        "        if \"жен\" in t or \"female\" in t:\n",
        "            return 0\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _age_from_text(txt) -> Optional[float]:\n",
        "        if not isinstance(txt, str):\n",
        "            return None\n",
        "        m = re.search(r\"(\\d{1,3})(?:[.,]\\d+)?\\s*(?:лет|год|года|years?)\", txt.lower())\n",
        "        if m:\n",
        "            return float(m.group(1))\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize_num(text: str) -> Optional[float]:\n",
        "        if not isinstance(text, str):\n",
        "            return None\n",
        "        m = re.search(r\"(\\d+[.,]?\\d*)\", text)\n",
        "        if not m:\n",
        "            return None\n",
        "        return float(m.group(1).replace(\",\", \".\"))\n",
        "\n",
        "    # role/position grouping — ключи и наборы слов оформлены иначе\n",
        "    ROLE_KEYWORDS: Dict[str, List[str]] = {\n",
        "        \"dev\": [\"программист\", \"разработчик\", \"developer\", \"java\", \"python\", \"php\", \"frontend\", \"backend\", \"qa\"],\n",
        "        \"sys\": [\"системн\", \"администратор\", \"devops\", \"dba\", \"сетев\"],\n",
        "        \"mgr\": [\"менедж\", \"руководител\", \"начальник\", \"lead\", \"project\", \"product\"],\n",
        "        \"analyst\": [\"аналитик\", \"data\", \"analysis\", \"bi\"],\n",
        "        \"support\": [\"поддерж\", \"support\", \"helpdesk\", \"оператор\"],\n",
        "        \"marketing\": [\"маркет\", \"seo\", \"контент\", \"дизайн\"],\n",
        "        \"engineer\": [\"инженер\", \"техник\", \"электрик\", \"монтаж\"],\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def _role_bucket(cls, title) -> str:\n",
        "        if not isinstance(title, str):\n",
        "            return \"other\"\n",
        "        t = title.lower()\n",
        "        for bucket, kws in cls.ROLE_KEYWORDS.items():\n",
        "            if any(k in t for k in kws):\n",
        "                return bucket\n",
        "        return \"other\"\n",
        "\n",
        "    # ---------------- city / trip ----------------\n",
        "\n",
        "    @staticmethod\n",
        "    def _city_root(txt) -> str:\n",
        "        if not isinstance(txt, str):\n",
        "            return \"unknown\"\n",
        "        return txt.split(\",\")[0].strip().lower()\n",
        "\n",
        "    MAJOR_CITIES = {\"москва\", \"мск\", \"зеленоград\", \"подольск\", \"люберцы\", \"домодедово\"}\n",
        "    PETER_CITIES = {\"санкт-петербург\", \"спб\", \"saint petersburg\", \"st. petersburg\"}\n",
        "    LARGE_SET = {\n",
        "        \"новосибирск\", \"екатеринбург\", \"казань\", \"нижний новгород\", \"челябинск\",\n",
        "        \"красноярск\", \"омск\", \"самара\", \"уфа\", \"воронеж\", \"пермь\", \"ростов-на-дону\", \"краснодар\"\n",
        "    }\n",
        "    MEDIUM_SET = {\n",
        "        \"волгоград\", \"тюмень\", \"саратов\", \"тольятти\", \"ижевск\", \"иркутск\", \"хабаровск\",\n",
        "        \"барнаул\", \"ульяновск\", \"ярославль\", \"томск\", \"владивосток\", \"махачкала\"\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def _city_tier(cls, city_name: str) -> str:\n",
        "        if not isinstance(city_name, str):\n",
        "            return \"unknown\"\n",
        "        c = city_name.lower()\n",
        "        if any(k in c for k in cls.MAJOR_CITIES):\n",
        "            return \"moscow\"\n",
        "        if any(k in c for k in cls.PETER_CITIES):\n",
        "            return \"spb\"\n",
        "        if c in cls.LARGE_SET:\n",
        "            return \"large_city\"\n",
        "        if c in cls.MEDIUM_SET:\n",
        "            return \"medium_city\"\n",
        "        return \"small_city\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _trip_pref(txt):\n",
        "        if not isinstance(txt, str):\n",
        "            return np.nan\n",
        "        s = txt.lower()\n",
        "        if re.search(r\"не готов\", s) or \"not prepared\" in s:\n",
        "            return \"no\"\n",
        "        if re.search(r\"редк\", s) or \"rare\" in s:\n",
        "            return \"rare\"\n",
        "        if re.search(r\"готов\", s) or \"prepared\" in s:\n",
        "            return \"yes\"\n",
        "        return np.nan\n",
        "\n",
        "    # ---------------- employment / schedule / exp ----------------\n",
        "\n",
        "    WORK_TYPE_MAP = {\n",
        "        \"полная занятость\": \"full_time\",\n",
        "        \"full time\": \"full_time\",\n",
        "        \"частичная занятость\": \"part_time\",\n",
        "        \"part time\": \"part_time\",\n",
        "        \"проектная работа\": \"project\",\n",
        "        \"project work\": \"project\",\n",
        "        \"стажировка\": \"project\",\n",
        "        \"volunteering\": \"project\",\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def _extract_work_types(cls, txt) -> List[str]:\n",
        "        if not isinstance(txt, str):\n",
        "            return []\n",
        "        parts = [p.strip() for p in re.split(r\",|\\||;\", txt.lower()) if p.strip()]\n",
        "        mapped = {cls.WORK_TYPE_MAP[p] for p in parts if p in cls.WORK_TYPE_MAP}\n",
        "        return list(mapped)\n",
        "\n",
        "    SCHEDULE_MAP = {\n",
        "        \"полный день\": \"full_day\",\n",
        "        \"full day\": \"full_day\",\n",
        "        \"гибкий график\": \"flexible\",\n",
        "        \"flexible schedule\": \"flexible\",\n",
        "        \"сменный график\": \"rotational\",\n",
        "        \"удаленная работа\": \"remote\",\n",
        "        \"remote working\": \"remote\",\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def _extract_schedules(cls, txt) -> List[str]:\n",
        "        if not isinstance(txt, str):\n",
        "            return []\n",
        "        parts = [p.strip() for p in re.split(r\",|\\||;\", txt.lower()) if p.strip()]\n",
        "        return list({cls.SCHEDULE_MAP[p] for p in parts if p in cls.SCHEDULE_MAP})\n",
        "\n",
        "    @staticmethod\n",
        "    def _experience_years(txt) -> Optional[float]:\n",
        "        if not isinstance(txt, str) or \"не указано\" in txt.lower():\n",
        "            return None\n",
        "        # захватываем года и месяцы\n",
        "        m = re.search(r\"(?:(\\d+)\\s*(?:лет|год|г\\.|years?))?\\s*(?:(\\d+)\\s*(?:месяц|мес|months?))?\", txt.lower())\n",
        "        if not m:\n",
        "            return None\n",
        "        yrs = int(m.group(1)) if m.group(1) else 0\n",
        "        months = int(m.group(2)) if m.group(2) else 0\n",
        "        return yrs + months / 12.0\n",
        "\n",
        "    # ---------------- column encoders ----------------\n",
        "\n",
        "    def _enc_gender_age(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"Пол, возраст\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"gender\"] = out[src].map(self._gender_from_text).fillna(-1).astype(float)\n",
        "        out[\"age\"] = out[src].map(self._age_from_text)\n",
        "        out[\"age\"] = out[\"age\"].clip(lower=18, upper=75)\n",
        "        out[\"age\"] = out[\"age\"].fillna(out[\"age\"].median())\n",
        "        out.drop(columns=[src], inplace=True)\n",
        "        return out\n",
        "\n",
        "    def _enc_position_guess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"Ищет работу на должность:\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"role_group\"] = out[src].map(self._role_bucket)\n",
        "        out = pd.get_dummies(out, columns=[\"role_group\"], drop_first=True)\n",
        "        out.drop(columns=[src], inplace=True)\n",
        "        return out\n",
        "\n",
        "    def _enc_location_trip(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"Город\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"city_raw\"] = out[src].map(self._city_root)\n",
        "        out[\"city_tier\"] = out[\"city_raw\"].map(self._city_tier)\n",
        "        out[\"trip_readiness\"] = out[src].map(self._trip_pref)\n",
        "        # если нет значения — поставить самый частый\n",
        "        if out[\"trip_readiness\"].isna().any():\n",
        "            most = out[\"trip_readiness\"].mode()\n",
        "            if not most.empty:\n",
        "                out[\"trip_readiness\"] = out[\"trip_readiness\"].fillna(most[0])\n",
        "        out = pd.get_dummies(out, columns=[\"city_tier\", \"trip_readiness\"], drop_first=True)\n",
        "        out.drop(columns=[src, \"city_raw\"], inplace=True)\n",
        "        return out\n",
        "\n",
        "    def _enc_work_types(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"Занятость\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"work_types\"] = out[src].map(self._extract_work_types)\n",
        "        out[\"is_full_time\"] = out[\"work_types\"].apply(lambda lst: 1 if \"full_time\" in lst else 0)\n",
        "        out[\"is_part_time\"] = out[\"work_types\"].apply(lambda lst: 1 if \"part_time\" in lst else 0)\n",
        "        out[\"is_project\"] = out[\"work_types\"].apply(lambda lst: 1 if \"project\" in lst else 0)\n",
        "        out.drop(columns=[src, \"work_types\"], inplace=True)\n",
        "        return out\n",
        "\n",
        "    def _enc_schedule_flags(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"График\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"schedules\"] = out[src].map(self._extract_schedules)\n",
        "        for flag in (\"full_day\", \"flexible\", \"rotational\", \"remote\"):\n",
        "            out[f\"sch_{flag}\"] = out[\"schedules\"].apply(lambda lst: 1 if flag in lst else 0)\n",
        "        out.drop(columns=[src, \"schedules\"], inplace=True)\n",
        "        return out\n",
        "\n",
        "    def _enc_experience(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"Опыт (двойное нажатие для полной версии)\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"years_exp\"] = out[src].map(self._experience_years)\n",
        "        med = out[\"years_exp\"].median()\n",
        "        out[\"years_exp\"] = out[\"years_exp\"].fillna(med).clip(lower=0, upper=45)\n",
        "        out.drop(columns=[src], inplace=True)\n",
        "        return out\n",
        "\n",
        "    def _enc_car(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"Авто\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"has_car\"] = out[src].apply(lambda v: 1 if isinstance(v, str) and \"автомобиль\" in v.lower() else 0)\n",
        "        out.drop(columns=[src], inplace=True)\n",
        "        return out\n",
        "\n",
        "    def _drop_if_present(self, df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
        "        out = df.copy()\n",
        "        for c in cols:\n",
        "            if c in out.columns:\n",
        "                out.drop(columns=[c], inplace=True)\n",
        "        return out\n",
        "\n",
        "    def _enc_previous_position(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"Последеняя/нынешняя должность\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"prev_role_group\"] = out[src].map(self._group_prev_position)\n",
        "        out = pd.get_dummies(out, columns=[\"prev_role_group\"], drop_first=True)\n",
        "        out.drop(columns=[src], inplace=True)\n",
        "        return out\n",
        "\n",
        "    # немного отличная логика группировки для предыдущей должности (другой стиль)\n",
        "    PREV_ROLE_MAP = {\n",
        "        \"dev\": [\"программист\", \"разработчик\", \"developer\"],\n",
        "        \"sysadmin\": [\"системн\", \"администратор\", \"devops\"],\n",
        "        \"manager\": [\"руковод\", \"директор\", \"начальник\", \"lead\"],\n",
        "        \"analyst\": [\"аналитик\", \"data\", \"analysis\"],\n",
        "        \"support\": [\"поддерж\", \"support\", \"helpdesk\"],\n",
        "        \"marketing_sales\": [\"маркет\", \"продаж\", \"контент\"],\n",
        "        \"engineer\": [\"инженер\", \"техник\"]\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def _group_prev_position(cls, text) -> str:\n",
        "        if not isinstance(text, str):\n",
        "            return \"other\"\n",
        "        t = text.lower()\n",
        "        for k, kws in cls.PREV_ROLE_MAP.items():\n",
        "            if any(kw in t for kw in kws):\n",
        "                return k\n",
        "        return \"other\"\n",
        "\n",
        "    # образование — другой способ маппинга\n",
        "    EDUC_MAP = {\n",
        "        \"higher\": [\"высшее\", \"бакалавр\", \"магистр\", \"университет\", \"academy\"],\n",
        "        \"vocational\": [\"среднее специальное\", \"колледж\", \"техникум\", \"vocational\", \"пту\"],\n",
        "        \"incomplete\": [\"неоконченное\", \"incomplete\", \"не закончено\"],\n",
        "        \"secondary\": [\"среднее образование\", \"школа\", \"high school\"]\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def _parse_educ(cls, text) -> List[str]:\n",
        "        if not isinstance(text, str):\n",
        "            return [\"other\"]\n",
        "        t = text.lower()\n",
        "        found = {k for k, kws in cls.EDUC_MAP.items() if any(kw in t for kw in kws)}\n",
        "        return list(found) if found else [\"other\"]\n",
        "\n",
        "    def _enc_education(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        src = \"Образование и ВУЗ\"\n",
        "        if src not in df.columns:\n",
        "            return df\n",
        "        out = df.copy()\n",
        "        out[\"educ_levels\"] = out[src].map(self._parse_educ)\n",
        "        out[\"has_higher_edu\"] = out[\"educ_levels\"].apply(lambda lst: 1 if \"higher\" in lst else 0)\n",
        "        out.drop(columns=[src, \"educ_levels\"], inplace=True)\n",
        "        return out\n",
        "\n",
        "    # ---------------- main pipeline ----------------\n",
        "\n",
        "    def _run(self, data: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        if data is None:\n",
        "            return None\n",
        "\n",
        "        df = data.copy()\n",
        "\n",
        "        df = self._enc_gender_age(df)\n",
        "        df = self._enc_position_guess(df)\n",
        "        df = self._enc_location_trip(df)\n",
        "        df = self._enc_work_types(df)\n",
        "        df = self._enc_schedule_flags(df)\n",
        "        df = self._enc_experience(df)\n",
        "        df = self._enc_car(df)\n",
        "        df = self._drop_if_present(df, [\"Последенее/нынешнее место работы\", \"Обновление резюме\"])\n",
        "        df = self._enc_previous_position(df)\n",
        "        df = self._enc_education(df)\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "ZV79ZNi93Wpa"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================================\n",
        "## КЛАССЫ РАЗДЕЛИТЕЛЯ И ЭКСПОТЕРА ДАННЫХ\n",
        "============================================================================"
      ],
      "metadata": {
        "id": "PZ2EvLyq3-Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TargetSeparator(HandlerBase):\n",
        "    \"\"\"Выделение X / y из DataFrame без вмешательства в pipeline.\"\"\"\n",
        "\n",
        "    COMMON_TARGET_NAMES: List[str] = [\n",
        "        \"target\", \"y\", \"label\", \"salary\", \"ЗП\", \"Зарплата\"\n",
        "    ]\n",
        "\n",
        "    def __init__(self, target_col: Optional[str] = None) -> None:\n",
        "        super().__init__()\n",
        "        self.target_col = target_col\n",
        "\n",
        "    def _run(self, df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        # в цепочке просто пропускаем дальше\n",
        "        return df\n",
        "\n",
        "    def extract(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "        target = self._resolve_target(df)\n",
        "        features = df.drop(columns=[target])\n",
        "        labels = df[target]\n",
        "        return features, labels\n",
        "\n",
        "    def _resolve_target(self, df: pd.DataFrame) -> str:\n",
        "        if self.target_col is not None:\n",
        "            if self.target_col not in df.columns:\n",
        "                raise KeyError(f\"Target column '{self.target_col}' not found\")\n",
        "            return self.target_col\n",
        "\n",
        "        for name in self.COMMON_TARGET_NAMES:\n",
        "            if name in df.columns:\n",
        "                return name\n",
        "\n",
        "        # fallback — последняя колонка\n",
        "        return df.columns[-1]"
      ],
      "metadata": {
        "id": "PrOH2UWX4Gtb"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NumpyDatasetWriter(HandlerBase):\n",
        "    \"\"\"Сохраняет X / y в формате .npy рядом с исходным CSV.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        source_path: Path | str,\n",
        "        x_filename: str = \"X.npy\",\n",
        "        y_filename: str = \"y.npy\",\n",
        "        target_col: Optional[str] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.output_dir = Path(source_path).parent\n",
        "        self.x_filename = x_filename\n",
        "        self.y_filename = y_filename\n",
        "        self.target_col = target_col\n",
        "\n",
        "    def _run(self, df: Optional[pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        if df is None:\n",
        "            return None\n",
        "\n",
        "        splitter = TargetSeparator(self.target_col)\n",
        "        X, y = splitter.extract(df)\n",
        "\n",
        "        x_path = self.output_dir / self.x_filename\n",
        "        y_path = self.output_dir / self.y_filename\n",
        "\n",
        "        logger.info(\"Persisting datasets: X=%s, y=%s\", x_path, y_path)\n",
        "\n",
        "        np.save(x_path, X.to_numpy(dtype=float, copy=True))\n",
        "        np.save(y_path, y.to_numpy(dtype=float, copy=True))\n",
        "\n",
        "        logger.info(\"Numpy datasets saved successfully\")\n",
        "        return df"
      ],
      "metadata": {
        "id": "5K2V4MgV4Ha4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================================\n",
        "## ФУНКЦИИ ДЛЯ ПОСТРОЕНИЯ И ЗАПУСКА ПАЙПЛАЙНА\n",
        "============================================================================"
      ],
      "metadata": {
        "id": "C65RMBQR5B7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pipeline(csv_file: Path, target_col: str | None = None) -> HandlerBase:\n",
        "    \"\"\"Конструирует цепочку обработки данных для CSV.\"\"\"\n",
        "\n",
        "    # === обработчики ===\n",
        "    loader = CSVSource(csv_file)\n",
        "    cleaner = TextSanitizer()\n",
        "    salary_parser = SalaryConverter(salary_col=\"ЗП\")\n",
        "    outlier_handler = SalaryOutlierHandler(target=\"ЗП\", strategy=\"clip\")\n",
        "    completeness_checker = DataCompleteness()\n",
        "    feature_encoder = ProfileEncoder()\n",
        "    target_splitter = TargetSeparator(target_col)\n",
        "    npy_saver = NumpyDatasetWriter(csv_file)\n",
        "\n",
        "    # === сборка цепочки ===\n",
        "    loader \\\n",
        "        .link_next(cleaner) \\\n",
        "        .link_next(salary_parser) \\\n",
        "        .link_next(outlier_handler) \\\n",
        "        .link_next(completeness_checker) \\\n",
        "        .link_next(feature_encoder) \\\n",
        "        .link_next(target_splitter) \\\n",
        "        .link_next(npy_saver)\n",
        "\n",
        "    return loader"
      ],
      "metadata": {
        "id": "MzFRAeOm5Dx7"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(csv_file: Path, target_col: str | None = None) -> pd.DataFrame:\n",
        "    \"\"\"Запускает обработку CSV и возвращает DataFrame.\"\"\"\n",
        "    pipeline = create_pipeline(csv_file, target_col)\n",
        "    return pipeline.execute(None)"
      ],
      "metadata": {
        "id": "e1S9qPEo5Fnu"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================================\n",
        "## ЗАПУСК ПАЙПЛАЙНА ОБРАБОТКИ ДАННЫХ\n",
        "============================================================================"
      ],
      "metadata": {
        "id": "KXPB7Ojc5INe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = Path(\"hh.csv\")\n",
        "target_col = \"ЗП\"\n",
        "\n",
        "if not input_path.exists():\n",
        "    raise FileNotFoundError(f\"File not found: {input_path}\")\n",
        "\n",
        "if input_path.suffix.lower() != \".csv\":\n",
        "    raise ValueError(\"Unsupported file type. Please provide a .csv file.\")\n"
      ],
      "metadata": {
        "id": "xv6TiGgy5G8W"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# запуск пайплайна\n",
        "df = run_pipeline(input_path, target_col)"
      ],
      "metadata": {
        "id": "4-1K3joN7Xnu"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# просмотр первых строк\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "VqGyMJXP5Pg6",
        "outputId": "84f2c461-148d-4f78-9228-399ec541f990"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ЗП  gender   age  role_group_dev  role_group_engineer  \\\n",
              "0  27000.0     1.0  42.0           False                False   \n",
              "1  60000.0     1.0  41.0           False                 True   \n",
              "2  65000.0     1.0  44.0           False                False   \n",
              "3  70000.0     1.0  43.0            True                False   \n",
              "4  45000.0     1.0  39.0           False                False   \n",
              "\n",
              "   role_group_marketing  role_group_mgr  role_group_other  role_group_support  \\\n",
              "0                 False           False             False               False   \n",
              "1                 False           False             False               False   \n",
              "2                 False           False             False               False   \n",
              "3                 False           False             False               False   \n",
              "4                 False           False             False               False   \n",
              "\n",
              "   role_group_sys  ...  years_exp  has_car  prev_role_group_dev  \\\n",
              "0            True  ...        0.0        1                False   \n",
              "1           False  ...        0.0        0                False   \n",
              "2            True  ...        0.0        0                False   \n",
              "3           False  ...        0.0        0                False   \n",
              "4            True  ...        0.0        0                False   \n",
              "\n",
              "   prev_role_group_engineer  prev_role_group_manager  \\\n",
              "0                     False                    False   \n",
              "1                      True                    False   \n",
              "2                     False                    False   \n",
              "3                     False                    False   \n",
              "4                     False                    False   \n",
              "\n",
              "   prev_role_group_marketing_sales  prev_role_group_other  \\\n",
              "0                            False                  False   \n",
              "1                            False                  False   \n",
              "2                            False                  False   \n",
              "3                            False                   True   \n",
              "4                            False                  False   \n",
              "\n",
              "   prev_role_group_support  prev_role_group_sysadmin  has_higher_edu  \n",
              "0                    False                      True               0  \n",
              "1                    False                     False               1  \n",
              "2                    False                      True               1  \n",
              "3                    False                     False               1  \n",
              "4                    False                      True               1  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e9e09dd-df6d-4f46-ac07-a3d623b98043\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ЗП</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>role_group_dev</th>\n",
              "      <th>role_group_engineer</th>\n",
              "      <th>role_group_marketing</th>\n",
              "      <th>role_group_mgr</th>\n",
              "      <th>role_group_other</th>\n",
              "      <th>role_group_support</th>\n",
              "      <th>role_group_sys</th>\n",
              "      <th>...</th>\n",
              "      <th>years_exp</th>\n",
              "      <th>has_car</th>\n",
              "      <th>prev_role_group_dev</th>\n",
              "      <th>prev_role_group_engineer</th>\n",
              "      <th>prev_role_group_manager</th>\n",
              "      <th>prev_role_group_marketing_sales</th>\n",
              "      <th>prev_role_group_other</th>\n",
              "      <th>prev_role_group_support</th>\n",
              "      <th>prev_role_group_sysadmin</th>\n",
              "      <th>has_higher_edu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e9e09dd-df6d-4f46-ac07-a3d623b98043')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e9e09dd-df6d-4f46-ac07-a3d623b98043 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e9e09dd-df6d-4f46-ac07-a3d623b98043');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    }
  ]
}