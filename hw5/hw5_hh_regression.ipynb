{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "=============================================================================\n",
        "# КЛАСС ДЛЯ ОБУЧЕНИЯ И ОЦЕНКИ РЕГРЕССИИ\n",
        "============================================================================="
      ],
      "metadata": {
        "id": "H5JixJ3T_m4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h_0eMf8G--0j"
      },
      "outputs": [],
      "source": [
        "# Системные и утилитарные модули\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, Any, Tuple\n",
        "\n",
        "# Работа с данными и модели\n",
        "import numpy as np  # для загрузки и работы с массивами .npy\n",
        "from sklearn.linear_model import Ridge  # линейная регрессия с L2-регуляризацией\n",
        "from sklearn.preprocessing import StandardScaler  # стандартизация признаков\n",
        "from sklearn.pipeline import Pipeline  # упрощение сборки последовательности трансформаций и модели\n",
        "\n",
        "# Метрики\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,        # среднеквадратичная ошибка\n",
        "    mean_absolute_error,       # средняя абсолютная ошибка\n",
        "    r2_score,                  # коэффициент детерминации\n",
        "    explained_variance_score,\n",
        ")\n",
        "\n",
        "# Подбор гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV, KFold  # CV и подбор сетки параметров"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=============================================================================\n",
        "## ОСНОВНОЙ КЛАСС\n",
        "============================================================================="
      ],
      "metadata": {
        "id": "oNotQzLHBVzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class RidgeTrainer:\n",
        "    \"\"\"\n",
        "    Класс, инкапсулирующий весь процесс:\n",
        "      1. Загрузка данных из .npy\n",
        "      2. Создание pipeline: стандартизация + Ridge\n",
        "      3. GridSearchCV по alpha с KFold\n",
        "      4. Расчёт метрик на train\n",
        "      5. Красивый отчёт с результатами\n",
        "\n",
        "    Атрибуты:\n",
        "        x_path: путь к файлу с X (.npy)\n",
        "        y_path: путь к файлу с y (.npy)\n",
        "        cv_splits: количество фолдов в KFold\n",
        "        random_state: фиксируем случайность для повторяемости\n",
        "        n_jobs: сколько потоков использовать для GridSearch\n",
        "        refit_on: метрика, по которой будет рефититься лучшая модель\n",
        "    \"\"\"\n",
        "    x_path: str\n",
        "    y_path: str\n",
        "    cv_splits: int = 5\n",
        "    random_state: int = 42\n",
        "    n_jobs: int = -1\n",
        "    refit_on: str = \"neg_mean_squared_error\"\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Загрузка данных\n",
        "    # -------------------------------------------------------------------------\n",
        "    def load_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Загружает данные из указанных .npy файлов.\n",
        "        Возвращает X и y, где y преобразуется в 1D массив через ravel().\n",
        "        \"\"\"\n",
        "        X = np.load(self.x_path)\n",
        "        y = np.load(self.y_path).ravel()\n",
        "        return X, y\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Построение pipeline\n",
        "    # -------------------------------------------------------------------------\n",
        "    def build_pipeline(self) -> Pipeline:\n",
        "        \"\"\"\n",
        "        Создаёт pipeline:\n",
        "          - StandardScaler: стандартизируем признаки\n",
        "          - Ridge: регрессия с L2 регуляризацией\n",
        "        \"\"\"\n",
        "        pipeline = Pipeline(\n",
        "            steps=[\n",
        "                (\"scaler\", StandardScaler()),  # стандартизация\n",
        "                (\"regressor\", Ridge()),        # регрессор\n",
        "            ]\n",
        "        )\n",
        "        return pipeline\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Подготовка сетки гиперпараметров\n",
        "    # -------------------------------------------------------------------------\n",
        "    def make_param_grid(self, start: float = 0.1, stop: float = 15.0, step: float = 0.25) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Создаёт сетку alpha для Ridge.\n",
        "        Можно изменить start/stop/step для других диапазонов.\n",
        "        \"\"\"\n",
        "        alphas = np.arange(start, stop, step)\n",
        "        return {\"regressor__alpha\": alphas}\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Запуск GridSearchCV\n",
        "    # -------------------------------------------------------------------------\n",
        "    def run_grid_search(self, X: np.ndarray, y: np.ndarray) -> GridSearchCV:\n",
        "        \"\"\"\n",
        "        Запускает GridSearchCV:\n",
        "          - pipeline: StandardScaler + Ridge\n",
        "          - param_grid: alpha\n",
        "          - KFold с shuffle\n",
        "          - scoring: MSE, MAE, R2 (refit по выбранной метрике)\n",
        "        \"\"\"\n",
        "        model = self.build_pipeline()\n",
        "        param_grid = self.make_param_grid()\n",
        "\n",
        "        cv = KFold(n_splits=self.cv_splits, shuffle=True, random_state=self.random_state)\n",
        "\n",
        "        scoring = {\n",
        "            \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
        "            \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
        "            \"r2\": \"r2\",\n",
        "        }\n",
        "\n",
        "        grid = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=param_grid,\n",
        "            scoring=scoring,\n",
        "            refit=self.refit_on,\n",
        "            cv=cv,\n",
        "            n_jobs=self.n_jobs,\n",
        "            return_train_score=True,\n",
        "        )\n",
        "\n",
        "        grid.fit(X, y)\n",
        "        return grid\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Расчёт метрик на обучающей выборке\n",
        "    # -------------------------------------------------------------------------\n",
        "    def evaluate_on_train(self, estimator: Pipeline, X: np.ndarray, y: np.ndarray) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Предсказывает y на X и считает набор метрик:\n",
        "          - MSE, RMSE, MAE\n",
        "          - R2\n",
        "          - Explained Variance\n",
        "        \"\"\"\n",
        "        y_pred = estimator.predict(X)\n",
        "        mse = mean_squared_error(y, y_pred)\n",
        "        rmse = mse ** 0.5\n",
        "        mae = mean_absolute_error(y, y_pred)\n",
        "        r2 = r2_score(y, y_pred)\n",
        "        expl_var = explained_variance_score(y, y_pred)\n",
        "\n",
        "        return {\n",
        "            \"mse\": mse,\n",
        "            \"rmse\": rmse,\n",
        "            \"mae\": mae,\n",
        "            \"r2\": r2,\n",
        "            \"explained_variance\": expl_var,\n",
        "        }\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Форматирование вывода метрики\n",
        "    # -------------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def _format_metric(name: str, value: float, digits: int = 4) -> str:\n",
        "        \"\"\"\n",
        "        Красиво форматирует метрику для вывода.\n",
        "        \"\"\"\n",
        "        return f\"{name:20s}: {value:.{digits}f}\"\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Отчёт о результатах\n",
        "    # -------------------------------------------------------------------------\n",
        "    def report(self, grid: GridSearchCV, train_metrics: Dict[str, float]) -> None:\n",
        "        \"\"\"\n",
        "        Печатает компактный, структурированный отчёт:\n",
        "          - лучший alpha из GridSearch\n",
        "          - CV метрики (MSE, RMSE)\n",
        "          - метрики на train (MSE, RMSE, MAE, R2, Explained Variance)\n",
        "        \"\"\"\n",
        "        best_alpha = grid.best_params_.get(\"regressor__alpha\")\n",
        "        best_mse_cv = -grid.best_score_  # sklearn возвращает отрицательное MSE\n",
        "        best_rmse_cv = best_mse_cv ** 0.5\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"РЕЗУЛЬТАТЫ GRID SEARCH (CV)\".center(70))\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Лучший параметр alpha: {best_alpha}\")\n",
        "        print(self._format_metric(\"CV MSE\", best_mse_cv, digits=4))\n",
        "        print(self._format_metric(\"CV RMSE\", best_rmse_cv, digits=4))\n",
        "\n",
        "        print(\"\\n\" + \"-\" * 70)\n",
        "        print(\"МЕТРИКИ НА TRAIN (для сравнения)\".center(70))\n",
        "        print(\"-\" * 70)\n",
        "        for k, v in train_metrics.items():\n",
        "            digits = 4 if k in (\"r2\", \"explained_variance\") else 2\n",
        "            print(self._format_metric(k.upper(), v, digits=digits))\n",
        "\n",
        "        print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Главный метод для запуска всего процесса\n",
        "    # -------------------------------------------------------------------------\n",
        "    def run(self) -> dict[str, Any]:\n",
        "        \"\"\"\n",
        "        1. Загружает данные\n",
        "        2. Запускает GridSearchCV\n",
        "        3. Вычисляет метрики на train\n",
        "        4. Выводит отчёт\n",
        "        5. Возвращает словарь с результатами\n",
        "        \"\"\"\n",
        "        X, y = self.load_data()\n",
        "        grid = self.run_grid_search(X, y)\n",
        "        best_model = grid.best_estimator_\n",
        "        train_metrics = self.evaluate_on_train(best_model, X, y)\n",
        "        self.report(grid, train_metrics)\n",
        "\n",
        "        return {\n",
        "            \"grid_search\": grid,\n",
        "            \"best_model\": best_model,\n",
        "            \"train_metrics\": train_metrics,\n",
        "        }"
      ],
      "metadata": {
        "id": "Juv_hNLQBEGK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=============================================================================\n",
        "# ИСПОЛЬЗОВАНИЕ КЛАССА\n",
        "============================================================================="
      ],
      "metadata": {
        "id": "h_uknrh2BisE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = RidgeTrainer(\n",
        "    x_path=\"data/X.npy\",\n",
        "    y_path=\"data/y.npy\",\n",
        "    cv_splits=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    refit_on=\"neg_mean_squared_error\",\n",
        ")\n",
        "results = trainer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kjOHx7hBgnK",
        "outputId": "2977877b-2d0d-4997-d573-2928455d115f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "                     РЕЗУЛЬТАТЫ GRID SEARCH (CV)                      \n",
            "======================================================================\n",
            "Лучший параметр alpha: 14.849999999999998\n",
            "CV MSE              : 1615056089.7886\n",
            "CV RMSE             : 40187.7604\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "                   МЕТРИКИ НА TRAIN (для сравнения)                   \n",
            "----------------------------------------------------------------------\n",
            "MSE                 : 1612899742.79\n",
            "RMSE                : 40160.92\n",
            "MAE                 : 30704.33\n",
            "R2                  : 0.4181\n",
            "EXPLAINED_VARIANCE  : 0.4181\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}